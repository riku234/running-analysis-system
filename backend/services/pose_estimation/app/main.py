from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from typing import List, Dict, Any, Optional
import cv2
import mediapipe as mp
import numpy as np
import os
import json
import math
import csv
import time
from datetime import datetime
from pathlib import Path

app = FastAPI(
    title="Pose Estimation Service",
    description="å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ©ãƒ³ãƒŠãƒ¼ã®éª¨æ ¼ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆYOLO + MediaPipeï¼‰",
    version="1.0.0"
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MediaPipeã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
mp_pose = mp.solutions.pose
mp_draw = mp.solutions.drawing_utils

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

class VideoEstimationRequest(BaseModel):
    video_path: str
    confidence_threshold: Optional[float] = 0.5

class PoseEstimationRequest(BaseModel):
    video_id: str
    frame_paths: List[str]

class KeyPoint(BaseModel):
    x: float
    y: float
    z: float
    visibility: float

class FramePoseData(BaseModel):
    frame_number: int
    timestamp: float
    keypoints: List[KeyPoint]
    landmarks_detected: bool
    confidence_score: float

class PoseEstimationResponse(BaseModel):
    status: str
    message: str
    video_info: Dict[str, Any]
    pose_data: List[FramePoseData]
    summary: Dict[str, Any]

# =============================================================================
# OneEuroFilter ã‚¯ãƒ©ã‚¹ï¼ˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ç”¨ï¼‰
# =============================================================================
class LowPassFilter:
    """ãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ1æ¬¡IIRãƒ•ã‚£ãƒ«ã‚¿ï¼‰"""
    def __init__(self, alpha, init_value=None):
        self.__setAlpha(alpha)
        self.y = init_value
        self.s = init_value

    def __setAlpha(self, alpha):
        alpha = float(alpha)
        if alpha <= 0 or alpha > 1.0:
            self.alpha = 1.0  # ãƒ•ã‚£ãƒ«ã‚¿ãªã—
        else:
            self.alpha = alpha

    def filter(self, value, alpha=None):
        if alpha is not None:
            self.__setAlpha(alpha)
        if self.s is None:
            self.s = value
        else:
            self.s = self.alpha * value + (1.0 - self.alpha) * self.s
        return self.s

class OneEuroFilter:
    """1â‚¬ Filterï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ç”¨ï¼‰"""
    def __init__(self, t0, x0, min_cutoff=1.0, beta=0.0, d_cutoff=1.0):
        """
        Args:
            t0: åˆæœŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆç§’ï¼‰
            x0: åˆæœŸå€¤
            min_cutoff: ä½é€Ÿæ™‚ã®æœ€å°ã‚«ãƒƒãƒˆã‚ªãƒ•å‘¨æ³¢æ•°ï¼ˆä½ã„ã»ã©æ»‘ã‚‰ã‹ã ãŒé…å»¶å¢—ï¼‰
            beta: é€Ÿåº¦ä¿‚æ•°ï¼ˆé«˜ã„ã»ã©é«˜é€Ÿå‹•ä½œæ™‚ã®è¿½å¾“æ€§ãŒè‰¯ããªã‚‹ï¼é…å»¶æ¸›ï¼‰
            d_cutoff: å¾®åˆ†ãƒ•ã‚£ãƒ«ã‚¿ã®ã‚«ãƒƒãƒˆã‚ªãƒ•å‘¨æ³¢æ•°
        """
        self.frequency = 0.0
        self.min_cutoff = float(min_cutoff)
        self.beta = float(beta)
        self.d_cutoff = float(d_cutoff)
        self.x_filter = LowPassFilter(self.alpha(min_cutoff))
        self.dx_filter = LowPassFilter(self.alpha(d_cutoff))
        self.t_prev = t0
        self.x_filter.s = x0
        self.dx_filter.s = 0

    def alpha(self, cutoff):
        """ã‚«ãƒƒãƒˆã‚ªãƒ•å‘¨æ³¢æ•°ã‹ã‚‰ã‚¢ãƒ«ãƒ•ã‚¡å€¤ã‚’è¨ˆç®—"""
        if self.frequency <= 0:
            return 1.0
        te = 1.0 / self.frequency
        tau = 1.0 / (2 * math.pi * cutoff)
        return 1.0 / (1.0 + tau / te)

    def process(self, t, x):
        """ãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†ã‚’å®Ÿè¡Œ"""
        t_e = t - self.t_prev

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒæ›´æ–°ã•ã‚Œã¦ã„ãªã„ã€ã¾ãŸã¯ç•°å¸¸ãªå ´åˆã®ã‚¬ãƒ¼ãƒ‰å‡¦ç†
        if t_e <= 0.0:
            return self.x_filter.s if self.x_filter.s is not None else x
            
        self.frequency = 1.0 / t_e
        self.t_prev = t
        
        # å¾®åˆ†ï¼ˆé€Ÿåº¦ï¼‰ã®è¨ˆç®—ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        dx = (x - self.x_filter.s) * self.frequency
        edx = self.dx_filter.filter(dx, self.alpha(self.d_cutoff))
        
        # é€Ÿåº¦ã«å¿œã˜ãŸã‚«ãƒƒãƒˆã‚ªãƒ•å‘¨æ³¢æ•°ã®å‹•çš„èª¿æ•´
        cutoff = self.min_cutoff + self.beta * abs(edx)
        return self.x_filter.filter(x, self.alpha(cutoff))

@app.get("/")
async def health_check():
    """ã‚µãƒ¼ãƒ“ã‚¹ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "healthy", "service": "pose_estimation"}

def extract_pose_from_video(video_path: str, confidence_threshold: float = 0.5, enable_debug_log: bool = False) -> PoseEstimationResponse:
    """
    å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éª¨æ ¼ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        confidence_threshold: ä¿¡é ¼åº¦ã®é–¾å€¤
        enable_debug_log: ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã‹ã©ã†ã‹
        
    Returns:
        éª¨æ ¼ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æ¤œå‡ºçµæœ
    """
    if not os.path.exists(video_path):
        raise HTTPException(status_code=404, detail=f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
    
    # å‡¦ç†æ™‚é–“è¨ˆæ¸¬ç”¨
    timing_info = {
        'total_start': time.time(),
        'video_open': 0,
        'mediapipe_init': 0,
        'frame_processing': [],
        'outlier_rejection': [],
        'oneeuro_filter': [],
        'debug_log_save': 0,
        'total_end': 0
    }
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ç”¨ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆenable_debug_logãŒTrueã®å ´åˆã®ã¿ï¼‰
    debug_data = {
        'raw_mediapipe': [],  # MediaPipeã®ç”Ÿãƒ‡ãƒ¼ã‚¿
        'filtered_oneeuro': [],  # OneEuroFilterå¾Œã®ãƒ‡ãƒ¼ã‚¿
        'timestamps': []
    } if enable_debug_log else None
    
    # OpenCVã§å‹•ç”»ã‚’é–‹ã
    timing_info['video_open'] = time.time()
    cap = cv2.VideoCapture(video_path)
    
    # å‹•ç”»æƒ…å ±ã®å–å¾—
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    video_info = {
        "fps": fps,
        "total_frames": total_frames,
        "duration_seconds": duration,
        "width": width,
        "height": height
    }
    
    pose_data_list = []
    frame_number = 0
    
    # OneEuroFilterç”¨ã®ãƒ•ã‚£ãƒ«ã‚¿è¾æ›¸ï¼ˆ33å€‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ Ã— 3æ¬¡å…ƒ(x,y,z)ï¼‰
    # ã‚­ãƒ¼: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹, å€¤: {'x': OneEuroFilter, 'y': OneEuroFilter, 'z': OneEuroFilter}
    filters = {}
    
    # Outlier Rejectionç”¨ï¼šå‰å›ã®è‰¯å¥½ãªåº§æ¨™ã‚’ä¿æŒ
    # ã‚­ãƒ¼: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹, å€¤: {'x': float, 'y': float, 'z': float}
    last_valid_landmarks = {}
    
    # Outlier Rejectionç”¨ï¼šé€£ç¶šç•°å¸¸å€¤ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    # ã‚­ãƒ¼: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹, å€¤: é€£ç¶šç•°å¸¸å€¤ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
    outlier_count = {}
    
    # ID Switchæ¤œå‡ºã¨æ§‹é€ çš„åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ç”¨ã®å±¥æ­´ï¼ˆéå»2ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ä¿æŒï¼‰
    keypoint_history = []
    
    # OneEuroFilterã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯å‹•ããŒé€Ÿã„ã®ã§ beta ã‚’å°‘ã—å¤§ãã‚ã«è¨­å®šï¼‰
    MIN_CUTOFF = 0.5  # é™æ­¢æ™‚ã®ãƒ–ãƒ¬è»½æ¸›ï¼ˆæ»‘ã‚‰ã‹é‡è¦–ï¼‰
    BETA = 0.01       # å‹•ãå‡ºã—ã®åå¿œé€Ÿåº¦ï¼ˆãƒ©ã‚°ã‚ˆã‚Šæ»‘ã‚‰ã‹ã•å„ªå…ˆï¼‰
    D_CUTOFF = 1.0    # å¾®åˆ†ãƒ•ã‚£ãƒ«ã‚¿ã®ã‚«ãƒƒãƒˆã‚ªãƒ•å‘¨æ³¢æ•°
    
    # Outlier Rejectionã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    JUMP_THRESHOLD = 0.1  # 1ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã“ã‚Œä»¥ä¸Šå‹•ã„ãŸã‚‰ã€Œç•°å¸¸ã€ã¨ã¿ãªã™ï¼ˆç”»é¢ã®10%ï¼‰
    MAX_CONSECUTIVE_OUTLIERS = 5  # é€£ç¶šã—ã¦ç•°å¸¸å€¤ãŒå‡ºç¶šã‘ã‚‹å ´åˆã®æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆã“ã‚Œã‚’è¶…ãˆãŸã‚‰å¼·åˆ¶æ›´æ–°ï¼‰
    
    # MediaPipe Poseã®åˆæœŸåŒ–ï¼ˆç²¾åº¦å‘ä¸Šã®ãŸã‚è¨­å®šã‚’æœ€é©åŒ–ï¼‰
    timing_info['mediapipe_init'] = time.time()
    with mp_pose.Pose(
        static_image_mode=False,
        model_complexity=2,  # æœ€é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ï¼ˆ0=è»½é‡, 1=æ¨™æº–, 2=é«˜ç²¾åº¦ï¼‰
        enable_segmentation=False,
        min_detection_confidence=0.5,  # èª¤æ¤œå‡ºã‚’é˜²ããŸã‚æ¨™æº–å€¤ã«æˆ»ã™
        min_tracking_confidence=0.5  # èª¤æ¤œå‡ºã‚’é˜²ããŸã‚æ¨™æº–å€¤ã«æˆ»ã™
    ) as pose:
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # ç”»åƒã®å‰å‡¦ç†ï¼šç²¾åº¦å‘ä¸Šã®ãŸã‚ã®é«˜åº¦ãªå‰å‡¦ç†
            # 1. è§£åƒåº¦ã‚’ä¸Šã’ã‚‹ï¼ˆå°ã•ã„å‹•ç”»ã®å ´åˆï¼‰
            scale_factor = max(1.0, 640.0 / max(width, height))
            if scale_factor > 1.0:
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
            
            # 2. ãƒã‚¤ã‚ºé™¤å»ï¼ˆã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ï¼‰
            frame = cv2.GaussianBlur(frame, (3, 3), 0)
            
            # 3. ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚¨ãƒƒã‚¸ã‚’ä¿ã¡ãªãŒã‚‰ãƒã‚¤ã‚ºé™¤å»ï¼‰
            frame = cv2.bilateralFilter(frame, 5, 50, 50)
            
            # 4. ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ï¼ˆCLAHEï¼‰
            lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))  # clipLimitã‚’ä¸Šã’ã¦ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–
            l = clahe.apply(l)
            frame = cv2.merge([l, a, b])
            frame = cv2.cvtColor(frame, cv2.COLOR_LAB2BGR)
            
            # 5. ã‚·ãƒ£ãƒ¼ãƒ—åŒ–ï¼ˆã‚¨ãƒƒã‚¸å¼·èª¿ï¼‰
            kernel = np.array([[-1, -1, -1],
                              [-1,  9, -1],
                              [-1, -1, -1]])
            frame = cv2.filter2D(frame, -1, kernel * 0.15 + np.eye(3) * 0.55)  # ã‚·ãƒ£ãƒ¼ãƒ—åŒ–ã‚’å¼·åŒ–
            
            # BGR to RGBå¤‰æ›ï¼ˆMediaPipeç”¨ï¼‰
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # ãƒãƒ¼ã‚ºæ¤œå‡ºã®å®Ÿè¡Œ
            results = pose.process(rgb_frame)
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®è¨ˆç®—
            timestamp = frame_number / fps if fps > 0 else 0
            
            keypoints = []
            landmarks_detected = False
            confidence_score = 0.0
            
            if results.pose_landmarks:
                # å…¨ä½“ã®æ¤œå‡ºä¿¡é ¼åº¦ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆèª¤æ¤œå‡ºã‚’é˜²ããŸã‚ï¼‰
                # ä¸»è¦ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆè‚©ã€è…°ã€è†ã€è¶³é¦–ï¼‰ã®å¹³å‡visibilityã‚’è¨ˆç®—
                key_landmark_indices = [11, 12, 23, 24, 25, 26, 27, 28]  # å·¦å³ã®è‚©ã€è…°ã€è†ã€è¶³é¦–
                key_visibilities = [results.pose_landmarks.landmark[i].visibility 
                                   for i in key_landmark_indices 
                                   if i < len(results.pose_landmarks.landmark)]
                avg_key_visibility = np.mean(key_visibilities) if key_visibilities else 0.0
                
                # ä¸»è¦ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®å¹³å‡visibilityãŒä½ã„å ´åˆã¯æ¤œå‡ºã‚’ç„¡è¦–ï¼ˆèª¤æ¤œå‡ºã®å¯èƒ½æ€§ï¼‰
                if avg_key_visibility < 0.3:
                    landmarks_detected = False
                    confidence_score = 0.0
                else:
                    landmarks_detected = True
                    confidence_scores = []
                
                # å„ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡ºï¼ˆOutlier Rejection â†’ OneEuroFilterã§ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰
                current_keypoints = []
                raw_keypoints_frame = []  # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šMediaPipeã®ç”Ÿãƒ‡ãƒ¼ã‚¿
                filtered_keypoints_frame = []  # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šOneEuroFilterå¾Œã®ãƒ‡ãƒ¼ã‚¿
                
                for i, landmark in enumerate(results.pose_landmarks.landmark):
                    # MediaPipeã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    if enable_debug_log:
                        raw_keypoints_frame.append({
                            'index': i,
                            'x': landmark.x,
                            'y': landmark.y,
                            'z': landmark.z,
                            'visibility': landmark.visibility
                        })
                    
                    # Outlier Rejection: ç•°å¸¸ãªã€Œé£›ã³ã€ã‚’æ¤œå‡ºã—ã¦å‰å›ã®å€¤ã‚’æ¡ç”¨
                    processed_x, processed_y, processed_z = landmark.x, landmark.y, landmark.z
                    
                    if i not in last_valid_landmarks:
                        # åˆå›ãƒ•ãƒ¬ãƒ¼ãƒ ã¯ãã®ã¾ã¾æ¡ç”¨
                        last_valid_landmarks[i] = {'x': landmark.x, 'y': landmark.y, 'z': landmark.z}
                        outlier_count[i] = 0
                    else:
                        prev = last_valid_landmarks[i]
                        
                        # ç§»å‹•è·é›¢ï¼ˆãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã®ç°¡æ˜“ç‰ˆï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
                        dist = abs(landmark.x - prev['x']) + abs(landmark.y - prev['y'])
                        
                        if dist > JUMP_THRESHOLD:
                            # ç•°å¸¸ãªé£›ã³ã‚’æ¤œçŸ¥
                            outlier_count[i] = outlier_count.get(i, 0) + 1
                            
                            # é€£ç¶šã—ã¦ç•°å¸¸å€¤ãŒå‡ºç¶šã‘ã‚‹å ´åˆã®å¯¾ç­–
                            if outlier_count[i] >= MAX_CONSECUTIVE_OUTLIERS:
                                # å¼·åˆ¶æ›´æ–°ï¼ˆæ¤œå‡ºãŒå®Œå…¨ã«å¤±æ•—ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
                                last_valid_landmarks[i] = {'x': landmark.x, 'y': landmark.y, 'z': landmark.z}
                                outlier_count[i] = 0
                                processed_x, processed_y, processed_z = landmark.x, landmark.y, landmark.z
                            else:
                                # å‰å›ã®å€¤ã‚’ç¶­æŒï¼ˆãƒ•ãƒªãƒ¼ã‚ºï¼‰
                                processed_x, processed_y, processed_z = prev['x'], prev['y'], prev['z']
                        else:
                            # æ­£å¸¸ç¯„å›²ãªã‚‰æ›´æ–°
                            last_valid_landmarks[i] = {'x': landmark.x, 'y': landmark.y, 'z': landmark.z}
                            outlier_count[i] = 0
                    
                    # OneEuroFilterã§ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆOutlier Rejectionå¾Œã®å€¤ã‚’ä½¿ç”¨ï¼‰
                    if i not in filters:
                        # ãƒ•ã‚£ãƒ«ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯åˆæœŸåŒ–
                        filters[i] = {
                            'x': OneEuroFilter(timestamp, processed_x, min_cutoff=MIN_CUTOFF, beta=BETA, d_cutoff=D_CUTOFF),
                            'y': OneEuroFilter(timestamp, processed_y, min_cutoff=MIN_CUTOFF, beta=BETA, d_cutoff=D_CUTOFF),
                            'z': OneEuroFilter(timestamp, processed_z, min_cutoff=MIN_CUTOFF, beta=BETA, d_cutoff=D_CUTOFF)
                        }
                        smoothed_x, smoothed_y, smoothed_z = processed_x, processed_y, processed_z
                    else:
                        # ãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†ã®å®Ÿè¡Œï¼ˆOutlier Rejectionå¾Œã®å€¤ã‚’ä½¿ç”¨ï¼‰
                        smoothed_x = filters[i]['x'].process(timestamp, processed_x)
                        smoothed_y = filters[i]['y'].process(timestamp, processed_y)
                        smoothed_z = filters[i]['z'].process(timestamp, processed_z)
                    
                    # OneEuroFilterå¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    if enable_debug_log:
                        filtered_keypoints_frame.append({
                            'index': i,
                            'x': smoothed_x,
                            'y': smoothed_y,
                            'z': smoothed_z,
                            'visibility': landmark.visibility
                        })
                    
                    keypoint = KeyPoint(
                        x=smoothed_x,
                        y=smoothed_y,
                        z=smoothed_z,
                        visibility=landmark.visibility
                    )
                    current_keypoints.append(keypoint)
                    confidence_scores.append(landmark.visibility)
                
                # ãƒ‡ãƒãƒƒã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆenable_debug_logãŒTrueã®å ´åˆã®ã¿ï¼‰
                if enable_debug_log and debug_data is not None:
                    debug_data['raw_mediapipe'].append(raw_keypoints_frame)
                    debug_data['filtered_oneeuro'].append(filtered_keypoints_frame)
                    debug_data['timestamps'].append(timestamp)
                
                # å·¦å³ã®åŒºåˆ¥ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã«ã‚ˆã‚‹åŒä¸€æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆ1-Aï¼‰
                if len(current_keypoints) > 28 and len(keypoint_history) > 0:
                    # MediaPipeã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©
                    left_shoulder_idx = 11
                    right_shoulder_idx = 12
                    left_hip_idx = 23
                    right_hip_idx = 24
                    left_knee_idx = 25
                    right_knee_idx = 26
                    left_ankle_idx = 27
                    right_ankle_idx = 28
                    
                    # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
                    prev_keypoints = keypoint_history[-1]
                    
                    # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
                    def euclidean_distance(kp1: KeyPoint, kp2: KeyPoint) -> float:
                        """2ã¤ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆé–“ã®ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’è¨ˆç®—"""
                        dx = kp1.x - kp2.x
                        dy = kp1.y - kp2.y
                        dz = kp1.z - kp2.z
                        return np.sqrt(dx*dx + dy*dy + dz*dz)
                    
                    # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã«ã‚ˆã‚‹ID Switchæ¤œå‡ºï¼ˆ1-Aï¼‰
                    # å·¦å³ã®è¶³é¦–ã«ã¤ã„ã¦ã€ID Switchã‚’æ¤œå‡º
                    if (len(prev_keypoints) > right_ankle_idx and
                        current_keypoints[left_ankle_idx].visibility > 0.3 and
                        current_keypoints[right_ankle_idx].visibility > 0.3 and
                        prev_keypoints[left_ankle_idx].visibility > 0.3 and
                        prev_keypoints[right_ankle_idx].visibility > 0.3):
                        
                        # è·é›¢ã‚’è¨ˆç®—
                        # æ­£ã—ã„çµ„ã¿åˆã‚ã›ï¼ˆå·¦â†’å·¦ã€å³â†’å³ï¼‰
                        dist_left_to_left = euclidean_distance(prev_keypoints[left_ankle_idx], current_keypoints[left_ankle_idx])
                        dist_right_to_right = euclidean_distance(prev_keypoints[right_ankle_idx], current_keypoints[right_ankle_idx])
                        dist_correct = dist_left_to_left + dist_right_to_right
                        
                        # é€†ã®çµ„ã¿åˆã‚ã›ï¼ˆå·¦â†’å³ã€å³â†’å·¦ï¼‰
                        dist_left_to_right = euclidean_distance(prev_keypoints[left_ankle_idx], current_keypoints[right_ankle_idx])
                        dist_right_to_left = euclidean_distance(prev_keypoints[right_ankle_idx], current_keypoints[left_ankle_idx])
                        dist_swapped = dist_left_to_right + dist_right_to_left
                        
                        # ID SwitchãŒç™ºç”Ÿã—ã¦ã„ã‚‹å ´åˆï¼ˆé€†ã®æ–¹ãŒè¿‘ã„ï¼‰
                        if dist_swapped < dist_correct * 0.8:  # 20%ä»¥ä¸Šè¿‘ã„å ´åˆã¯å…¥ã‚Œæ›¿ãˆ
                            # å·¦å³ã®è¶³é¦–ã‚’å…¥ã‚Œæ›¿ãˆï¼ˆæ–°ã—ã„KeyPointã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼‰
                            left_ankle_data = current_keypoints[left_ankle_idx]
                            right_ankle_data = current_keypoints[right_ankle_idx]
                            current_keypoints[left_ankle_idx] = KeyPoint(
                                x=right_ankle_data.x,
                                y=right_ankle_data.y,
                                z=right_ankle_data.z,
                                visibility=right_ankle_data.visibility
                            )
                            current_keypoints[right_ankle_idx] = KeyPoint(
                                x=left_ankle_data.x,
                                y=left_ankle_data.y,
                                z=left_ankle_data.z,
                                visibility=left_ankle_data.visibility
                            )
                    
                    # å·¦å³ã®è†ã«ã¤ã„ã¦ã‚‚åŒæ§˜ã«ãƒã‚§ãƒƒã‚¯
                    if (len(prev_keypoints) > right_knee_idx and
                        current_keypoints[left_knee_idx].visibility > 0.3 and
                        current_keypoints[right_knee_idx].visibility > 0.3 and
                        prev_keypoints[left_knee_idx].visibility > 0.3 and
                        prev_keypoints[right_knee_idx].visibility > 0.3):
                        
                        dist_left_to_left = euclidean_distance(prev_keypoints[left_knee_idx], current_keypoints[left_knee_idx])
                        dist_right_to_right = euclidean_distance(prev_keypoints[right_knee_idx], current_keypoints[right_knee_idx])
                        dist_correct = dist_left_to_left + dist_right_to_right
                        
                        dist_left_to_right = euclidean_distance(prev_keypoints[left_knee_idx], current_keypoints[right_knee_idx])
                        dist_right_to_left = euclidean_distance(prev_keypoints[right_knee_idx], current_keypoints[left_knee_idx])
                        dist_swapped = dist_left_to_right + dist_right_to_left
                        
                        if dist_swapped < dist_correct * 0.8:
                            # å·¦å³ã®è†ã‚’å…¥ã‚Œæ›¿ãˆï¼ˆæ–°ã—ã„KeyPointã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼‰
                            left_knee_data = current_keypoints[left_knee_idx]
                            right_knee_data = current_keypoints[right_knee_idx]
                            current_keypoints[left_knee_idx] = KeyPoint(
                                x=right_knee_data.x,
                                y=right_knee_data.y,
                                z=right_knee_data.z,
                                visibility=right_knee_data.visibility
                            )
                            current_keypoints[right_knee_idx] = KeyPoint(
                                x=left_knee_data.x,
                                y=left_knee_data.y,
                                z=left_knee_data.z,
                                visibility=left_knee_data.visibility
                            )
                    
                    # å·¦å³ã®è…°ã«ã¤ã„ã¦ã‚‚åŒæ§˜ã«ãƒã‚§ãƒƒã‚¯
                    if (len(prev_keypoints) > right_hip_idx and
                        current_keypoints[left_hip_idx].visibility > 0.3 and
                        current_keypoints[right_hip_idx].visibility > 0.3 and
                        prev_keypoints[left_hip_idx].visibility > 0.3 and
                        prev_keypoints[right_hip_idx].visibility > 0.3):
                        
                        dist_left_to_left = euclidean_distance(prev_keypoints[left_hip_idx], current_keypoints[left_hip_idx])
                        dist_right_to_right = euclidean_distance(prev_keypoints[right_hip_idx], current_keypoints[right_hip_idx])
                        dist_correct = dist_left_to_left + dist_right_to_right
                        
                        dist_left_to_right = euclidean_distance(prev_keypoints[left_hip_idx], current_keypoints[right_hip_idx])
                        dist_right_to_left = euclidean_distance(prev_keypoints[right_hip_idx], current_keypoints[left_hip_idx])
                        dist_swapped = dist_left_to_right + dist_right_to_left
                        
                        if dist_swapped < dist_correct * 0.8:
                            # å·¦å³ã®è…°ã‚’å…¥ã‚Œæ›¿ãˆï¼ˆæ–°ã—ã„KeyPointã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼‰
                            left_hip_data = current_keypoints[left_hip_idx]
                            right_hip_data = current_keypoints[right_hip_idx]
                            current_keypoints[left_hip_idx] = KeyPoint(
                                x=right_hip_data.x,
                                y=right_hip_data.y,
                                z=right_hip_data.z,
                                visibility=right_hip_data.visibility
                            )
                            current_keypoints[right_hip_idx] = KeyPoint(
                                x=left_hip_data.x,
                                y=left_hip_data.y,
                                z=left_hip_data.z,
                                visibility=left_hip_data.visibility
                            )
                    
                    # å·¦å³ã®è‚©ã«ã¤ã„ã¦ã‚‚åŒæ§˜ã«ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ã‚ˆã‚Šå®‰å®šæ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ï¼‰
                    if (len(prev_keypoints) > right_shoulder_idx and
                        current_keypoints[left_shoulder_idx].visibility > 0.3 and
                        current_keypoints[right_shoulder_idx].visibility > 0.3 and
                        prev_keypoints[left_shoulder_idx].visibility > 0.3 and
                        prev_keypoints[right_shoulder_idx].visibility > 0.3):
                        
                        dist_left_to_left = euclidean_distance(prev_keypoints[left_shoulder_idx], current_keypoints[left_shoulder_idx])
                        dist_right_to_right = euclidean_distance(prev_keypoints[right_shoulder_idx], current_keypoints[right_shoulder_idx])
                        dist_correct = dist_left_to_left + dist_right_to_right
                        
                        dist_left_to_right = euclidean_distance(prev_keypoints[left_shoulder_idx], current_keypoints[right_shoulder_idx])
                        dist_right_to_left = euclidean_distance(prev_keypoints[right_shoulder_idx], current_keypoints[left_shoulder_idx])
                        dist_swapped = dist_left_to_right + dist_right_to_left
                        
                        if dist_swapped < dist_correct * 0.8:
                            # å·¦å³ã®è‚©ã‚’å…¥ã‚Œæ›¿ãˆï¼ˆæ–°ã—ã„KeyPointã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼‰
                            left_shoulder_data = current_keypoints[left_shoulder_idx]
                            right_shoulder_data = current_keypoints[right_shoulder_idx]
                            current_keypoints[left_shoulder_idx] = KeyPoint(
                                x=right_shoulder_data.x,
                                y=right_shoulder_data.y,
                                z=right_shoulder_data.z,
                                visibility=right_shoulder_data.visibility
                            )
                            current_keypoints[right_shoulder_idx] = KeyPoint(
                                x=left_shoulder_data.x,
                                y=left_shoulder_data.y,
                                z=left_shoulder_data.z,
                                visibility=left_shoulder_data.visibility
                            )
                    
                    # æ§‹é€ çš„åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ï¼ˆè†ã¨è¶³é¦–ã®é–¢ä¿‚ï¼‰
                    # å·¦è†(25)ã¨å·¦è¶³é¦–(27)ã®é–¢ä¿‚
                    if (current_keypoints[left_knee_idx].visibility > 0.3 and 
                        current_keypoints[left_ankle_idx].visibility > 0.3):
                        # å·¦è¶³é¦–ã¯å·¦è†ã‚ˆã‚Šä¸‹ï¼ˆyåº§æ¨™ãŒå¤§ãã„ï¼‰ã§ã‚ã‚‹ã¹ã
                        if current_keypoints[left_ankle_idx].y < current_keypoints[left_knee_idx].y - 0.15:
                            # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®å€¤ã‚’ä½¿ç”¨ï¼ˆæ–°ã—ã„KeyPointã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼‰
                            if len(keypoint_history) > 0 and len(keypoint_history[-1]) > left_ankle_idx:
                                prev_ankle = keypoint_history[-1][left_ankle_idx]
                                current_keypoints[left_ankle_idx] = KeyPoint(
                                    x=prev_ankle.x,
                                    y=prev_ankle.y,
                                    z=prev_ankle.z,
                                    visibility=prev_ankle.visibility
                                )
                    
                    # å³è†(26)ã¨å³è¶³é¦–(28)ã®é–¢ä¿‚
                    if (current_keypoints[right_knee_idx].visibility > 0.3 and 
                        current_keypoints[right_ankle_idx].visibility > 0.3):
                        # å³è¶³é¦–ã¯å³è†ã‚ˆã‚Šä¸‹ï¼ˆyåº§æ¨™ãŒå¤§ãã„ï¼‰ã§ã‚ã‚‹ã¹ã
                        if current_keypoints[right_ankle_idx].y < current_keypoints[right_knee_idx].y - 0.15:
                            # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®å€¤ã‚’ä½¿ç”¨ï¼ˆæ–°ã—ã„KeyPointã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼‰
                            if len(keypoint_history) > 0 and len(keypoint_history[-1]) > right_ankle_idx:
                                prev_ankle = keypoint_history[-1][right_ankle_idx]
                                current_keypoints[right_ankle_idx] = KeyPoint(
                                    x=prev_ankle.x,
                                    y=prev_ankle.y,
                                    z=prev_ankle.z,
                                    visibility=prev_ankle.visibility
                                )
                
                # ID Switchæ¤œå‡ºã¨æ§‹é€ çš„åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ç”¨ã«å±¥æ­´ã‚’ä¿å­˜ï¼ˆOneEuroFilterã§æ—¢ã«ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ¸ˆã¿ï¼‰
                # keypoint_historyã¯ID Switchæ¤œå‡ºã¨æ§‹é€ çš„åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã€æœ€å°é™ã®å±¥æ­´ã‚’ä¿æŒ
                keypoint_history.append(current_keypoints)
                history_size = 2  # ID Switchæ¤œå‡ºç”¨ã«éå»2ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ä¿æŒ
                if len(keypoint_history) > history_size:
                    keypoint_history.pop(0)
                
                # OneEuroFilterã§æ—¢ã«ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ¸ˆã¿ãªã®ã§ã€ãã®ã¾ã¾ä½¿ç”¨
                keypoints = current_keypoints
                
                # å¹³å‡ä¿¡é ¼åº¦ã‚’è¨ˆç®—
                confidence_score = np.mean(confidence_scores) if confidence_scores else 0.0
            else:
                # æ¤œå‡ºå¤±æ•—æ™‚ã¯å±¥æ­´ã‹ã‚‰è£œé–“
                if len(keypoint_history) > 0:
                    landmarks_detected = True
                    # æœ€æ–°ã®å±¥æ­´ã‚’ä½¿ç”¨ï¼ˆä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
                    last_keypoints = keypoint_history[-1]
                    for last_kp in last_keypoints:
                        keypoints.append(KeyPoint(
                            x=last_kp.x,
                            y=last_kp.y,
                            z=last_kp.z,
                            visibility=last_kp.visibility * 0.6  # ä¿¡é ¼åº¦ã‚’40%æ¸›è¡°
                        ))
                    confidence_score = np.mean([kp.visibility for kp in keypoints]) if keypoints else 0.0
                else:
                    landmarks_detected = False
                    confidence_score = 0.0
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            frame_pose_data = FramePoseData(
                frame_number=frame_number,
                timestamp=timestamp,
                keypoints=keypoints,
                landmarks_detected=landmarks_detected,
                confidence_score=float(confidence_score)
            )
            
            pose_data_list.append(frame_pose_data)
            frame_number += 1
    
    cap.release()
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ï¼ˆenable_debug_logãŒTrueã§ã€ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
    if enable_debug_log and debug_data is not None and len(debug_data.get('raw_mediapipe', [])) > 0:
        try:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            video_name = Path(video_path).stem
            
            # JSONå½¢å¼ã§å‡ºåŠ›
            json_output_path = f"debug_coordinates_{video_name}_{timestamp_str}.json"
            with open(json_output_path, 'w', encoding='utf-8') as f:
                json.dump(debug_data, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“Š ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆJSONï¼‰ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {json_output_path}")
            
            # CSVå½¢å¼ã§å‡ºåŠ›ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã€ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã”ã¨ï¼‰
            csv_output_path = f"debug_coordinates_{video_name}_{timestamp_str}.csv"
            with open(csv_output_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
                writer.writerow([
                    'frame_number', 'timestamp', 'keypoint_index',
                    'raw_x', 'raw_y', 'raw_z', 'raw_visibility',
                    'filtered_x', 'filtered_y', 'filtered_z', 'filtered_visibility',
                    'diff_x', 'diff_y', 'diff_z'
                ])
                
                # ãƒ‡ãƒ¼ã‚¿è¡Œ
                for frame_idx in range(len(debug_data['raw_mediapipe'])):
                    raw_frame = debug_data['raw_mediapipe'][frame_idx]
                    filtered_frame = debug_data['filtered_oneeuro'][frame_idx]
                    timestamp = debug_data['timestamps'][frame_idx]
                    
                    for kp_idx in range(len(raw_frame)):
                        raw_kp = raw_frame[kp_idx]
                        filtered_kp = filtered_frame[kp_idx]
                        
                        # å·®åˆ†ã‚’è¨ˆç®—
                        diff_x = filtered_kp['x'] - raw_kp['x']
                        diff_y = filtered_kp['y'] - raw_kp['y']
                        diff_z = filtered_kp['z'] - raw_kp['z']
                        
                        writer.writerow([
                            frame_idx,
                            f"{timestamp:.6f}",
                            raw_kp['index'],
                            f"{raw_kp['x']:.6f}", f"{raw_kp['y']:.6f}", f"{raw_kp['z']:.6f}", f"{raw_kp['visibility']:.6f}",
                            f"{filtered_kp['x']:.6f}", f"{filtered_kp['y']:.6f}", f"{filtered_kp['z']:.6f}", f"{filtered_kp['visibility']:.6f}",
                            f"{diff_x:.6f}", f"{diff_y:.6f}", f"{diff_z:.6f}"
                        ])
            
            print(f"ğŸ“Š ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆCSVï¼‰ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {csv_output_path}")
            print(f"   - ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(debug_data['raw_mediapipe'])}")
            print(f"   - ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ•°: {len(debug_data['raw_mediapipe'][0]) if debug_data['raw_mediapipe'] else 0}")
        except Exception as e:
            print(f"âš ï¸ ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã®å‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    # ã‚µãƒãƒªãƒ¼æƒ…å ±ã®è¨ˆç®—
    detected_frames = sum(1 for pose_data in pose_data_list if pose_data.landmarks_detected)
    avg_confidence = np.mean([pose_data.confidence_score for pose_data in pose_data_list if pose_data.landmarks_detected]) if detected_frames > 0 else 0.0
    
    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—
    timing_info['total_end'] = time.time()
    total_time = timing_info['total_end'] - timing_info['total_start']
    video_open_time = timing_info['video_open'] - timing_info['total_start']
    # MediaPipeåˆæœŸåŒ–æ™‚é–“ï¼ˆmediapipe_initãŒ0ã®å ´åˆã¯0ã¨ã—ã¦æ‰±ã†ï¼‰
    if timing_info['mediapipe_init'] > 0:
        mediapipe_init_time = timing_info['mediapipe_init'] - timing_info['video_open']
        frame_processing_start = timing_info['mediapipe_init']
    else:
        mediapipe_init_time = 0.0
        frame_processing_start = timing_info['video_open']
    processing_time = timing_info['total_end'] - frame_processing_start
    
    summary = {
        "total_processed_frames": len(pose_data_list),
        "detected_pose_frames": detected_frames,
        "detection_rate": detected_frames / len(pose_data_list) if len(pose_data_list) > 0 else 0.0,
        "average_confidence": float(avg_confidence),
        "mediapipe_landmarks_count": 33,  # MediaPipe Poseã¯33å€‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
        "processing_time_seconds": round(total_time, 2),
        "frames_per_second": round(len(pose_data_list) / total_time, 2) if total_time > 0 else 0.0,
        "debug_log_enabled": enable_debug_log
    }
    
    # å‡¦ç†æ™‚é–“ã¨æ¤œå‡ºç‡ã®ãƒ­ã‚°å‡ºåŠ›
    print(f"â±ï¸  å‡¦ç†æ™‚é–“ã‚µãƒãƒªãƒ¼:")
    print(f"   - ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
    print(f"   - å‹•ç”»ã‚ªãƒ¼ãƒ—ãƒ³: {video_open_time:.2f}ç§’")
    print(f"   - MediaPipeåˆæœŸåŒ–: {mediapipe_init_time:.2f}ç§’")
    print(f"   - ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†: {processing_time:.2f}ç§’ ({len(pose_data_list)}ãƒ•ãƒ¬ãƒ¼ãƒ )")
    print(f"   - å‡¦ç†é€Ÿåº¦: {summary['frames_per_second']:.2f} FPS")
    print(f"ğŸ“Š æ¤œå‡ºçµæœã‚µãƒãƒªãƒ¼:")
    print(f"   - ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(pose_data_list)}")
    print(f"   - æ¤œå‡ºæˆåŠŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {detected_frames}")
    print(f"   - æ¤œå‡ºç‡: {summary['detection_rate']*100:.1f}%")
    print(f"   - å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}")
    if enable_debug_log:
        print(f"   - âš ï¸  ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°å‡ºåŠ›ãŒæœ‰åŠ¹ã§ã™ï¼ˆå‡¦ç†æ™‚é–“ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰")
    
    return PoseEstimationResponse(
        status="success",
        message=f"éª¨æ ¼æ¤œå‡ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚{detected_frames}/{len(pose_data_list)}ãƒ•ãƒ¬ãƒ¼ãƒ ã§å§¿å‹¢ã‚’æ¤œå‡º",
        video_info=video_info,
        pose_data=pose_data_list,
        summary=summary
    )

@app.post("/estimate", response_model=PoseEstimationResponse)
async def estimate_pose_from_video(request: VideoEstimationRequest):
    """
    å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éª¨æ ¼ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹
    
    Args:
        request: å‹•ç”»ãƒ‘ã‚¹ã¨è¨­å®šã‚’å«ã‚€ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        
    Returns:
        éª¨æ ¼ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æ¤œå‡ºçµæœ
    """
    try:
        result = extract_pose_from_video(
            video_path=request.video_path,
            confidence_threshold=request.confidence_threshold
        )
        return result
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"éª¨æ ¼æ¤œå‡ºå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )

@app.post("/estimate_legacy")
async def estimate_pose_legacy(request: PoseEstimationRequest):
    """
    ãƒ¬ã‚¬ã‚·ãƒ¼ API: å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰éª¨æ ¼ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹ï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰
    
    Args:
        request: å‹•ç”»IDã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        
    Returns:
        å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®éª¨æ ¼æ¤œå‡ºçµæœï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
    """
    # ãƒ€ãƒŸãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆæ—¢å­˜ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹äº’æ›æ€§ã®ãŸã‚ï¼‰
    return {
        "status": "success",
        "video_id": request.video_id,
        "total_frames": len(request.frame_paths),
        "detected_poses": len(request.frame_paths),
        "pose_data": [
            {
                "frame_number": i,
                "timestamp": i * 0.033,
                "keypoints": {
                    "nose": {"x": 0.5, "y": 0.3, "confidence": 0.95},
                    "left_shoulder": {"x": 0.4, "y": 0.4, "confidence": 0.92},
                    "right_shoulder": {"x": 0.6, "y": 0.4, "confidence": 0.91}
                }
            } for i in range(len(request.frame_paths))
        ],
        "model_info": {
            "mediapipe_version": "0.10.7",
            "detection_confidence": 0.5,
            "tracking_confidence": 0.5
        }
    }

@app.get("/models/info")
async def get_model_info():
    """ä½¿ç”¨ä¸­ã®AIãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
    return {
        "yolo": {
            "version": "YOLOv8n",
            "weights": "yolov8n.pt",
            "input_size": [640, 640]
        },
        "mediapipe": {
            "version": "0.10.0",
            "model": "pose_landmarker_heavy.task",
            "keypoints": 33
        }
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8002) 