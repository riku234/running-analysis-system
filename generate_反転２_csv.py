#!/usr/bin/env python3
"""
å…¨ãƒ•ãƒ¬ãƒ¼ãƒ éª¨æ ¼ãƒ‡ãƒ¼ã‚¿CSVç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ - ã€Œåè»¢ï¼’ã€
ç¾åœ¨è§£æã•ã‚ŒãŸå‹•ç”»ã®å…¨ãƒ•ãƒ¬ãƒ¼ãƒ éª¨æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã§å‡ºåŠ›ã—ã¾ã™
"""

import json
import pandas as pd
import os
from datetime import datetime

# MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åã®å®šç¾©
MEDIAPIPE_LANDMARKS = [
    "nose", "left_eye_inner", "left_eye", "left_eye_outer", 
    "right_eye_inner", "right_eye", "right_eye_outer",
    "left_ear", "right_ear", "mouth_left", "mouth_right",
    "left_shoulder", "right_shoulder", "left_elbow", "right_elbow",
    "left_wrist", "right_wrist", "left_pinky", "right_pinky",
    "left_index", "right_index", "left_thumb", "right_thumb",
    "left_hip", "right_hip", "left_knee", "right_knee",
    "left_ankle", "right_ankle", "left_heel", "right_heel",
    "left_foot_index", "right_foot_index"
]

# èº«ä½“éƒ¨ä½ãƒãƒƒãƒ”ãƒ³ã‚°
BODY_PARTS_MAP = {
    "nose": "é¡”", "left_eye_inner": "é¡”", "left_eye": "é¡”", "left_eye_outer": "é¡”",
    "right_eye_inner": "é¡”", "right_eye": "é¡”", "right_eye_outer": "é¡”", 
    "left_ear": "é¡”", "right_ear": "é¡”", "mouth_left": "é¡”", "mouth_right": "é¡”",
    "left_shoulder": "ä¸Šè‚¢", "right_shoulder": "ä¸Šè‚¢", "left_elbow": "ä¸Šè‚¢", 
    "right_elbow": "ä¸Šè‚¢", "left_wrist": "ä¸Šè‚¢", "right_wrist": "ä¸Šè‚¢", 
    "left_pinky": "ä¸Šè‚¢", "right_pinky": "ä¸Šè‚¢", "left_index": "ä¸Šè‚¢", 
    "right_index": "ä¸Šè‚¢", "left_thumb": "ä¸Šè‚¢", "right_thumb": "ä¸Šè‚¢",
    "left_hip": "ä½“å¹¹", "right_hip": "ä½“å¹¹",
    "left_knee": "ä¸‹è‚¢", "right_knee": "ä¸‹è‚¢", "left_ankle": "ä¸‹è‚¢", 
    "right_ankle": "ä¸‹è‚¢", "left_heel": "ä¸‹è‚¢", "right_heel": "ä¸‹è‚¢", 
    "left_foot_index": "ä¸‹è‚¢", "right_foot_index": "ä¸‹è‚¢"
}

def load_analysis_result(filename="current_analysis_result.json"):
    """è§£æçµæœJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    except json.JSONDecodeError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {filename} ã®JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
        return None

def extract_pose_data_to_csv(analysis_result, output_filename="åè»¢ï¼’.csv"):
    """è§£æçµæœã‹ã‚‰éª¨æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦CSVå½¢å¼ã§ä¿å­˜"""
    
    if not analysis_result:
        print("âŒ è§£æçµæœãƒ‡ãƒ¼ã‚¿ãŒç„¡åŠ¹ã§ã™")
        return False
    
    # pose_analysisã‹ã‚‰pose_dataã‚’å–å¾—
    pose_analysis = analysis_result.get("pose_analysis", {})
    pose_data = pose_analysis.get("pose_data", [])
    video_info = pose_analysis.get("video_info", {})
    
    if not pose_data:
        print("âŒ pose_dataãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    print(f"ğŸ“Š å‡¦ç†é–‹å§‹:")
    print(f"   ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(pose_data)}")
    print(f"   å‹•ç”»æƒ…å ±: {video_info.get('width', 'N/A')}x{video_info.get('height', 'N/A')} @ {video_info.get('fps', 'N/A')}fps")
    
    # CSVãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
    csv_data = []
    
    for frame_data in pose_data:
        frame_number = frame_data.get("frame_number", 0)
        timestamp = frame_data.get("timestamp", 0.0)
        confidence_score = frame_data.get("confidence_score", 0.0)
        keypoints = frame_data.get("keypoints", [])
        
        # keypointsãŒ33å€‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯
        if len(keypoints) != 33:
            print(f"âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ {frame_number}: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ•°ãŒç•°å¸¸ ({len(keypoints)}/33)")
            continue
        
        # å„ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’CSVè¡Œã¨ã—ã¦è¿½åŠ 
        for idx, keypoint in enumerate(keypoints):
            if idx < len(MEDIAPIPE_LANDMARKS):
                landmark_name = MEDIAPIPE_LANDMARKS[idx]
                body_part = BODY_PARTS_MAP.get(landmark_name, "ä¸æ˜")
                
                csv_data.append({
                    "frame_number": frame_number,
                    "timestamp": round(timestamp, 4),
                    "confidence_score": round(confidence_score, 3),
                    "landmark": landmark_name,
                    "x_coordinate": round(keypoint.get("x", 0.0), 6),
                    "y_coordinate": round(keypoint.get("y", 0.0), 6),
                    "visibility": round(keypoint.get("visibility", 0.0), 3),
                    "body_part": body_part
                })
    
    if not csv_data:
        print("âŒ CSVãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    
    # DataFrameã‚’ä½œæˆã—ã¦CSVã«ä¿å­˜
    df = pd.DataFrame(csv_data)
    df.to_csv(output_filename, index=False, encoding='utf-8')
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    print(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†!")
    print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å: {output_filename}")
    print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(output_filename):,} bytes ({os.path.getsize(output_filename) / (1024*1024):.2f} MB)")
    print(f"ğŸ“‹ ç·è¡Œæ•°: {len(df):,} è¡Œ")
    print(f"ğŸ“Š ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {df['frame_number'].nunique():,} ãƒ•ãƒ¬ãƒ¼ãƒ ")
    print(f"ğŸ“ ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ•°: {df['landmark'].nunique()} ç¨®é¡")
    print(f"ğŸ¥ å‹•ç”»æ™‚é–“: {df['timestamp'].max():.2f} ç§’")
    print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {os.path.abspath(output_filename)}")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    print(f"\nğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ (æœ€åˆã®5è¡Œ):")
    print(df.head().to_string(index=False))
    
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ¬ å…¨ãƒ•ãƒ¬ãƒ¼ãƒ éª¨æ ¼ãƒ‡ãƒ¼ã‚¿CSVç”Ÿæˆé–‹å§‹ - ã€Œåè»¢ï¼’ã€")
    print("=" * 60)
    
    # è§£æçµæœã‚’èª­ã¿è¾¼ã¿
    analysis_result = load_analysis_result()
    if not analysis_result:
        return
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    success = extract_pose_data_to_csv(analysis_result, "åè»¢ï¼’.csv")
    
    if success:
        print("\nğŸ‰ å‡¦ç†å®Œäº†! CSVãƒ•ã‚¡ã‚¤ãƒ«ã€Œåè»¢ï¼’.csvã€ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
    else:
        print("\nâŒ å‡¦ç†å¤±æ•—")

if __name__ == "__main__":
    main()
